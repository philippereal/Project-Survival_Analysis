---
title: "Lab 3 - Survival Analysis"
btitle: ""
author: "Philippe Real"
date: '`r format(Sys.time(), " %d %B, %Y")`'
abstract: "This is my abstract."
keywords: "Survival Analysis, R"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    fig_caption: yes
    keep_tex: yes
    number_sections: true
  word_document:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
---
```{r,echo=FALSE, eval=FALSE}
install.packages("KMsurv")
install.packages("tidyverse")
install.packages("survival")
```


# Exercice N°2 - Comparaison des approches analyse de survie et classification

On souhaite prévoir la probabilité de rechute (“recurrent”) à 24 mois. Pour cela, vous comparerez les méthodes de l’analyse de survie (modèles de Cox, survival random forests, ...) aux méthodes de classification. Les mesures de performances (notamment l’AUC) se feront sur un sous-échantillon de test formé de 20 à 30% des données (attention à bien stratifier !).

## Import des données wpc
```{r}
wpbc.names = read_csv("./wpbc.names",col_names = F)
wpbc = read_csv("./wpbc.data",col_names = F)
#paste0("V",c(1:30))
names(wpbc) = c("id","recur","time",paste0("V",c(1:30)),"tumor_size","lymph")
glimpse(wpbc)
```



```{r}

```

## Label pour la tâche de classification.

A partir de la variable  ``recur`` (rechute) variable binaire.

```{r}
wpbc = wpbc %>% mutate(id = factor(id)) %>% mutate( recur = recode_factor(recur , 'N' = FALSE, 'R' = TRUE ))
wpbc$time <- as.numeric(wpbc$time )
wpbc<-filter(wpbc,wpbc$lymph!="?")
wpbc$lymph <- as.numeric(wpbc$lymph )

```

```{r}
data.cox<-wpbc
data.cox$recur<-as.numeric(data.cox$recur)
#wpbc <- mutate(wpbc, Z=recode_factor(recur , 'N' = FALSE, 'R' = TRUE  ))
```


## Jeu de données de train et de test

En fixant la racine du générateur aléatoire (fonction R set.seed), créer un jeu de données de train et un de test, attention à stratifier.

```{r}
set.seed(123)
```

```{r}
data.cox1<-data.cox[data.cox$recur==1,]
train1 = sample(c(T, F), nrow(data.cox1), replace = T, prob = c(.75, .25))
dataTrain1<-data.cox1[train1,]
dataTest1<-data.cox1[!train1,]

data.cox2<-data.cox[data.cox$recur==2,]
train2 = sample(c(T, F), nrow(data.cox2), replace = T, prob = c(.75, .25))
dataTrain2<-data.cox2[train2,]
dataTest2<-data.cox2[!train2,]

dataTrain<-rbind(dataTrain1,dataTrain2)
dataTest<-rbind(dataTest1,dataTest2)
```


## Construction d'un modèle de Cox.

Avant de construire un mopdèle de Cox on commence par regarder la courbe de survie de Kplan-Meyer.

### Courbe de survie de Kaplan Meyer

```{r}
km.fit <- survfit(Surv(time, recur) ~ 1, data=dataTrain)
```

Prévision à 24 mois
```{r}
summary(km.fit,time=24)
```

La proba de rechute à 24 mois est de 1-0.84 = 0.16 soit 16% avec un IC au seuil de 95%  $IC_{.95}=$ [0.788; 0.897].

```{r}
library(ggfortify)
autoplot(km.fit,main="Fig 2-Courbes de Kaplan-Meier")

```

### Modèle de Cox complet

```{r}
V<-paste0("V",c(1:30))
f=formula(paste("Surv(time,recur)~tumor_size + + lymph + ",paste0(V, collapse = " + ")))
coxph.m.comp <- coxph(f, data = dataTrain)
```

```{r}
summary(coxph.m.comp)
```

### Sélection de variable par AIC 


```{r include=FALSE}
coxph.m.AIC<-stepAIC(coxph.m.comp)
```

```{r}
summary(coxph.m.AIC)
```
```{r}
cox.m.fit <-survfit(coxph.m.AIC)

```

```{r}
summary(cox.m.fit,time=24)

```

La probabilité de rechute à 24 mois est de 10% avec un $IC_{0.95}=[0.854,0948]$
La proba de recute à baissé (-6%) comparé à l'estimation de KM.


```{r}
par(mfrow=c(1,2))
autoplot(km.fit,main="Fig 2-Courbes de Kaplan-Meier")

autoplot(cox.m.fit,main="Fig 2-Courbes de survie")
```



## Constructkion d'un modèle de regression logistique.

### Modèle logit

```{r include=FALSE}
data.logit.Train<-dataTrain
data.logit.Train=data.logit.Train %>% mutate( rechute = data.logit.Train$time>24 & data.logit.Train$recur==2)
data.logit.Test<-dataTest
data.logit.Test=data.logit.Test %>% mutate( rechute = data.logit.Test$time>24 & data.logit.Test$recur==2)

```


```{r include=FALSE}
V<-paste0("V",c(1:30))
f.glm=formula(paste("rechute ~ 1 + tumor_size + lymph + ",paste0(V, collapse = " + ")))
m_logit.comp<-glm(f.glm,family = binomial,  data = data.logit.Train )

```

```{r}
summary(m_logit.comp)
```

* Sélection du modèle par AIC: $stepAIC$

```{r include=FALSE}
m_logit.BwdFwd <- step(m_logit.comp, data=data.logit.Train, direction="both")
```

```{r}
summary(m_logit.BwdFwd)
```

```{r}


```


## Prédire dans les 2 modèles les probabilités de rechute à 24 mois.

```{r}
prev_m_cox.comp <- predict(coxph.m.comp,newdata = dataTest, type = "risk" )
prev_m_cox.aic <- predict(coxph.m.AIC,newdata = dataTest, type = "risk" )
prev_m_logit.comp <- predict(m_logit.comp,newdata = data.logit.Test, type = "response" )
prev_m_logit.aic <- predict(m_logit.BwdFwd,newdata = data.logit.Test, type = "response" )


```

### Probabilité estimée d'avoir une rfechute à 24 mois

```{r fig.height=5, fig.width=10, echo=FALSE}
 
 pred_proba <- data.frame(
   #coxph.comp = prev_m_cox.comp,
   #coxph.aic = prev_m_cox.aic,
                         logit.comp = prev_m_logit.comp,
                         logit.aic = prev_m_logit.aic)
head(round(pred_proba,3),n=17)
```

### 5.2 Estimation au seuil de 0.5
On confronte les probabilités obtenues en 5.1 aux seuil de 0.5
Dés que la prévision dépasse 50% on prédit qu'il pleuvra demain.
```{r fig.height=7, fig.width=10, include=TRUE, paged.print=TRUE}
 pred_0.5 <- apply(pred_proba >=0.5, 2, factor,labels=c("FALSE","TRUE"))
 head(pred_0.5,n=7)
```


```{r }
### Evaluation de la moyenne de prédiction l'erreur de prédiction

mean(abs(prev_m_logit.comp - 1), na.rm = T)
mean(abs(prev_m_logit.aic - 1), na.rm = T)

#?predict
mean(abs(prev_m_logit.comp-!data.logit.Test[, "rechute"]), na.rm = T)
mean(abs(prev_m_logit.aic-!data.logit.Test[, "rechute"]), na.rm = T)

```

### 5.3 Pourcentage de réussite des modèles par rapport à l'observation
On compare maintenant les valeurs prédites aux valeurs observées.
On fait mieux que la moyenne, par contre on a très peu gagné par rapport au modèle saturé, entre 1% et 2%.
La méthode employée s'est révélée assez peu performante.

```{r message=FALSE, warning=FALSE, echo=FALSE}
 library(tidyverse)
 compare_PredObs <- data.frame(pred_0.5)
 compare_PredObs <- compare_PredObs %>% mutate(Observe=data.logit.Test$rechute) 
res<- compare_PredObs %>% summarise_all(funs( 100*mean(Observe==.))) %>% round(4)
head(res)
```


```{r}


```


```{r}


```

## Comparer les modèles en termes de précision (accuracy) et d’AUC.

Le meilleur estiamteur aura une aire sous la courbe le plus proche possible de 1.
La courbe idéale serait perpendiculaire aux abscisse du point origine jusqu'au point (0.1) puis prallèle jusqu'au point (1,1)
Si bien que l'aire sous cette courbe serait égale à 1.

```{r echo=TRUE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE, echo=FALSE}
#install.packages("plotROC")
require(plotROC)
df_roc <- pred_proba %>% mutate(obs = data.logit.Test$rechute) %>%
  gather(key = methode, value = score, logit.comp,logit.aic)
 ggplot(df_roc) + aes(d=obs,m=score,color=methode)# + geom_roc()+theme_classic()
```

```{r echo=TRUE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE, echo=FALSE}
#install.packages("plotROC")
require(plotROC)
df_roc <- pred_proba %>% mutate(obs = data.logit.Test$rechute) %>%
  gather(key = methode, value = score, logit.comp,logit.aic)
 ggplot(df_roc) + aes(d=obs,m=score,color=methode)# +theme_classic() #+geom_roc()
   
```

```{r}

```

```{r}


```


```{r}


```
